# ðŸ•¸ï¸ Website Scraper with MySQL Storage

This Python-based web scraper is designed to extract data from a target website and store the scraped data in a MySQL database for further analysis or processing.

## ðŸš€ Features

- Scrapes structured data from a website using `requests`, `BeautifulSoup`.
- Saves extracted data to a MySQL database.
- Modular and extensible codebase.
- Handles errors gracefully and ensures data integrity.

## ðŸ› ï¸ Tech Stack

- **Language:** Python 3.x  
- **Libraries:** 
  - `requests` (for fetching web pages)
  - `beautifulsoup4` (for parsing HTML)
  - `mysql-connector-python` (for database interaction)
- **Database:** MySQL

## ðŸ“¦ Setup Instructions

### 1. Clone the Repository

```bash
git clone https://github.com/yourusername/website-scraper.git
cd website-scraper
```

### 2. Install Dependencies

```bash
pip install -r requirements.txt
```

### 3. Configure MySQL

```bash
DB_CONFIG = {
    'host': 'localhost',
    'user': 'your_mysql_username',
    'password': 'your_mysql_password',
    'database': 'your_database_name'
}
```

### 4. Run the Scraper

```bash
python scraper.py
```

# ðŸ“ Project Structure

```bash
website-scraper/
â”‚
â”œâ”€â”€ config.py            # MySQL DB configuration
â”œâ”€â”€ scraper.py           # Main script to scrape and store data
â”œâ”€â”€ database.py          # DB connection and insert logic
â”œâ”€â”€ utils.py             # (Optional) Utility functions
â”œâ”€â”€ requirements.txt     # Python dependencies
â””â”€â”€ README.md            # Project documentation
```

# ðŸ§ª Example Output

Scraped data will be inserted into a table like:

```bash
CREATE TABLE scraped_data (
    id INT AUTO_INCREMENT PRIMARY KEY,
    title VARCHAR(255),
    url TEXT,
    content TEXT,
    scraped_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);
```

# âœ… Best Practices

> Avoid scraping sites without permission. Always check the siteâ€™s robots.txt.
> Respect rate limits by adding sleep() between requests.
> Implement retry logic for robustness.
> Sanitize and validate all scraped data before storing.

# ðŸ‘¨â€ðŸ’» Author
> Rajesh Ranjan
> GitHub : https://github.com/rajesh-ranjan-git/website-scraper | LinkedIn : https://www.linkedin.com/in/rajesh-ranjan-660b1b13a/